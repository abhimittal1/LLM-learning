{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdfdd16",
   "metadata": {},
   "source": [
    "## Agentic AI Tool Calling — How it Works\n",
    "\n",
    "Agentic AI works even though an LLM only performs next-token prediction because the model never directly executes tools; it only generates structured text that *describes* which tool should be used. The agent program then parses this output and performs the real action externally. In simple terms, the LLM acts as the **planner/brain**, while the program acts as the **executor/hands**.\n",
    "\n",
    "### Flow\n",
    "\n",
    "* User sends a query\n",
    "* LLM predicts structured text (JSON/function call style) indicating which tool to use\n",
    "* Agent code parses this text\n",
    "* Actual function/API is executed by the program\n",
    "* Tool result is returned back to the LLM\n",
    "* LLM generates the final natural language response\n",
    "\n",
    "### Key Idea\n",
    "\n",
    "* LLM → decides **what to do**\n",
    "* Tools → perform **the action**\n",
    "* Agent code → connects both\n",
    "\n",
    "### Common Tool Types\n",
    "\n",
    "* **API tools** → weather, email, payments, external services\n",
    "* **Search tools** → web search, database lookup, vector/RAG retrieval\n",
    "* **Code execution tools** → Python, SQL, calculations\n",
    "* **File tools** → read/write/summarize PDFs, images, documents\n",
    "* **Action tools** → schedule meetings, send messages, control devices\n",
    "\n",
    "### Note\n",
    "\n",
    "Frameworks like **LangChain** or models from **OpenAI** simply orchestrate this loop internally, but fundamentally it is still just token prediction combined with external code execution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1258ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ab6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai = OpenAI()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "Model = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59dd22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a helpful assistant for an Airline called FlightAI.\n",
    "Give short, courteous answers, no more than 1 sentence.\n",
    "Always be accurate. If you don't know the answer, say so.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39f73c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message , history):\n",
    "    history = [{\"role\": h[\"role\"] , \"content\": h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\" , \"content\": system_message}] + history + [{\"role\": \"user\" , \"content\": message}]\n",
    "    stream = openai.chat.completions.create(model=Model , messages=messages , stream=True)\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d4f2370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat , type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2be2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful function\n",
    "\n",
    "tickets = {\"london\": 100 , \"paris\": 120 , \"new york\": 300 , \"india\" : 400}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tools called for city : {destination_city}\")\n",
    "    price = tickets.get(destination_city.lower(), \"Sorry, we don't fly to that city.\")\n",
    "    return f\"The ticket price to {destination_city} is {price} rupees.\" if isinstance(price, int) else price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8e20d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools called for city : london\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The ticket price to london is 100 rupees.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"london\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd437af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a ticket to a destination city.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city to which the user wants to fly.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2525844",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e58669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=Model, messages=messages, tools=tools)\n",
    "\n",
    "    # if response.choices[0].finish_reason==\"tool_calls\": \n",
    "    while response.choices[0].finish_reason==\"tool_calls\": # this means that the model has called a tool and is waiting for the tool's response before it can continue generating a response to the user.\n",
    "        message = response.choices[0].message\n",
    "        response = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai.chat.completions.create(model=Model, messages=messages)\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01a66498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to write that function handle_tool_call:\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    if tool_call.function.name == \"get_ticket_price\":\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        city = arguments.get('destination_city')\n",
    "        price_details = get_ticket_price(city)\n",
    "        response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": price_details,\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7b1419b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7877\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7877/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools called for city : India\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e053cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bcaa4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4285b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
