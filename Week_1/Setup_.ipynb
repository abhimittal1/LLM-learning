{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40354ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: d:\\Coding\\LLM learning\\.venv\\Scripts\\python.exe\n",
      "Python version: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]\n",
      "Platform: Windows-10-10.0.26200-SP0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c54e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_import(lib_name, import_stmt):\n",
    "    try:\n",
    "        exec(import_stmt)\n",
    "        print(f\"✅ {lib_name} is working\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {lib_name} failed -> {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d322301e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NumPy is working\n",
      "✅ Pandas is working\n",
      "✅ Requests is working\n",
      "✅ Pydantic is working\n"
     ]
    }
   ],
   "source": [
    "test_import(\"NumPy\", \"import numpy as np\")\n",
    "test_import(\"Pandas\", \"import pandas as pd\")\n",
    "test_import(\"Requests\", \"import requests\")\n",
    "test_import(\"Pydantic\", \"from pydantic import BaseModel\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11dbd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Torch is working\n",
      "✅ Scikit-learn is working\n",
      "✅ Transformers is working\n",
      "✅ Sentence-Transformers is working\n"
     ]
    }
   ],
   "source": [
    "test_import(\"Torch\", \"import torch\")\n",
    "test_import(\"Scikit-learn\", \"import sklearn\")\n",
    "test_import(\"Transformers\", \"import transformers\")\n",
    "test_import(\"Sentence-Transformers\", \"from sentence_transformers import SentenceTransformer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd6bbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangChain is working\n",
      "✅ LangChain Community is working\n",
      "✅ LangChain Chroma is working\n",
      "✅ ChromaDB is working\n"
     ]
    }
   ],
   "source": [
    "test_import(\"LangChain\", \"import langchain\")\n",
    "test_import(\"LangChain Community\", \"import langchain_community\")\n",
    "test_import(\"LangChain Chroma\", \"import langchain_chroma\")\n",
    "test_import(\"ChromaDB\", \"import chromadb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e342bb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FastAPI is working\n",
      "✅ Flask is working\n",
      "✅ Uvicorn is working\n"
     ]
    }
   ],
   "source": [
    "test_import(\"FastAPI\", \"from fastapi import FastAPI\")\n",
    "test_import(\"Flask\", \"from flask import Flask\")\n",
    "test_import(\"Uvicorn\", \"import uvicorn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21242737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matplotlib is working\n",
      "✅ Plotly is working\n"
     ]
    }
   ],
   "source": [
    "test_import(\"Matplotlib\", \"import matplotlib.pyplot as plt\")\n",
    "test_import(\"Plotly\", \"import plotly.express as px\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f45562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array sum: 10\n",
      "DataFrame:\n",
      "    numbers\n",
      "0        1\n",
      "1        2\n",
      "2        3\n",
      "3        4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "arr = np.array([1, 2, 3, 4])\n",
    "df = pd.DataFrame({\"numbers\": arr})\n",
    "\n",
    "print(\"Array sum:\", arr.sum())\n",
    "print(\"DataFrame:\\n\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d775542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.9.1+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b2db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB test result: {'ids': [['1']], 'embeddings': None, 'documents': [['Hello world']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None]], 'distances': [[0.4976864159107208]]}\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"test_collection\")\n",
    "\n",
    "collection.add(\n",
    "    documents=[\"Hello world\", \"UV virtual env works\"],\n",
    "    ids=[\"1\", \"2\"]\n",
    ")\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[\"Hello\"],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "print(\"ChromaDB test result:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04918ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It sounds like you might be referring to the Joker character from Batman or perhaps just using \"joker\" to imply someone who jokes around. In either case, I can definitely share some fun facts or jokes! What specifically are you interested in?\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()   # auto-reads OPENAI_API_KEY\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \" are a joker\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
